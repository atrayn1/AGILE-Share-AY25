{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import streamlit.components.v1 as components\n",
    "import csv\n",
    "import string\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from datetime import datetime as dt\n",
    "from base64 import b64encode\n",
    "#import proximitypyhash as pph\n",
    "#import pygeohash as gh\n",
    "from streamlit_folium import st_folium\n",
    "from streamlit_folium import folium_static\n",
    "import folium\n",
    "import numpy as np\n",
    "\n",
    "from agile.filtering import query_location, query_date, query_adid, query_node\n",
    "from agile.mapping import data_map \n",
    "from agile.locations import locations_of_interest\n",
    "from agile.people import colocation\n",
    "from agile.prediction import double_cluster, get_top_N_clusters\n",
    "from agile.utils.tag import find_all_nearby_nodes\n",
    "from agile.utils.geocode import reverse_geocode\n",
    "from agile.utils.files import find, random_line, save, random_name, generate_aliases\n",
    "from agile.utils.dataframes import modify_and_sort_columns, clean_and_verify_columns\n",
    "from agile.profile import Profile\n",
    "from agile.samsreport import Report\n",
    "from agile.centrality import compute_top_centrality\n",
    "from agile.overview import adid_value_counts\n",
    "\n",
    "from streamlit_option_menu import option_menu\n",
    "import pygeohash as gh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/too_many_adids.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['datetime'] = pd.to_datetime(df['datetime'],errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = modify_and_sort_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting file reading\n",
      "ending file reading\n",
      "1368896 1500000\n",
      "WARNING: Due to the amount of ADIDs in your data, not every ADID was assigned an alias\n"
     ]
    }
   ],
   "source": [
    "aliases = generate_aliases(df)\n",
    "if len(aliases) < len(df['advertiser_id'].unique()):\n",
    "    print(\"WARNING: Due to the amount of ADIDs in your data, not every ADID was assigned an alias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10605"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['advertiser_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = []\n",
    "last = []\n",
    "name_list = []\n",
    "\n",
    "with open(find('../names/first.txt')) as F, open(find('../names/last.txt')) as L:\n",
    "    for line_f in F:\n",
    "        first.append(line_f.strip())\n",
    " \n",
    "    for line_l in L:\n",
    "        last.append(line_l.strip())\n",
    "        \n",
    "    for f in first:\n",
    "        for l in last:        \n",
    "            name_list.append(l + '-' + f)\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "adid_dict = {}\n",
    "for id in df['advertiser_id'].unique():\n",
    "    adid_dict[id] = name_list.pop(random.randrange(len(name_list)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADID Alias Error Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_string(length):\n",
    "    return ''.join(random.choices(string.ascii_letters + string.digits, k=length))\n",
    "\n",
    "def generate_unique_combinations(total_combinations):\n",
    "    generated_combinations = set()\n",
    "    while len(generated_combinations) < total_combinations:\n",
    "        generated_combinations.add(generate_random_string(10))  # Change the length of string if needed\n",
    "    return list(generated_combinations)\n",
    "\n",
    "def generate_datetime_objects(total_objects):\n",
    "    start_date = datetime(2000, 1, 1)\n",
    "    end_date = datetime(2023, 12, 31)\n",
    "    delta = end_date - start_date\n",
    "\n",
    "    datetime_objects = [start_date + timedelta(days=random.randint(0, delta.days)) for _ in range(total_objects)]\n",
    "    return datetime_objects\n",
    "\n",
    "def generate_random_numbers(total_numbers):\n",
    "    random_numbers = [random.random() for _ in range(total_numbers)]\n",
    "    return random_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique combinations generated: 1500000\n"
     ]
    }
   ],
   "source": [
    "total_combinations = 1500000\n",
    "combinations = generate_unique_combinations(total_combinations)\n",
    "print(f\"Total unique combinations generated: {len(combinations)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_datetime_objects = 1500000\n",
    "total_random_numbers = 1500000\n",
    "\n",
    "datetime_objects = generate_datetime_objects(total_datetime_objects)\n",
    "latitudes = generate_random_numbers(total_random_numbers)\n",
    "longitudes = generate_random_numbers(total_random_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_df = pd.DataFrame(columns=['datetime','advertiser_id','latitude','longitude','geohash'])\n",
    "testing_df['datetime'] = datetime_objects\n",
    "testing_df['advertiser_id'] = combinations\n",
    "testing_df['latitude'] = latitudes\n",
    "testing_df['longitude'] = longitudes\n",
    "testing_df['geohash'] = ['c25r0uhu56'] * len(testing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_df.to_csv('data/too_many_adids.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agile",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
